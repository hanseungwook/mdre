{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External imports \n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.distributions.mixture_same_family import MixtureSameFamily\n",
    "import torch.distributions as D\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Internal imports\n",
    "import sys; sys.path.insert(0, '..')\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DIMS = 1\n",
    "NUM_SAMPLES = 33000\n",
    "BS = 500\n",
    "NUM_EPOCHS = 800\n",
    "SEED = 10\n",
    "LR = 1e-2\n",
    "DROPOUT = 0.20\n",
    "DEVICE = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# Break by changing num datapoints, scales, means, or to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed for reproducibility\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model_cob = RatioCritic1D(dim_input=N_DIMS, dim_output=3, dropout=DROPOUT)\n",
    "# model.apply(weights_init)\n",
    "\n",
    "# Define optimizer\n",
    "optim_cob = torch.optim.Adam(model_cob.parameters(), lr=LR)\n",
    "\n",
    "# Define distributions\n",
    "p, q, m = get_dists_1d(mu1=-1., mu2=1., mu3=0, scale_p=0.1, scale_q=0.2, scale_m=1.0)\n",
    "\n",
    "# -5, 5, m_var=3.0\n",
    "# -10, 10, m_var=3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_samples = p.sample([1000])\n",
    "# q_samples = q.sample([1000])\n",
    "# m1_samples = m1.sample([1000])\n",
    "# m2_samples = m2.sample([1000])\n",
    "# m3_samples = m3.sample([1000])\n",
    "\n",
    "# plt.hist(p_samples.numpy(), density=True, histtype='stepfilled')\n",
    "# plt.hist(q_samples.numpy(), density=True, histtype='stepfilled')\n",
    "# plt.hist(m1_samples.numpy(), density=True, histtype='stepfilled')\n",
    "# plt.hist(m2_samples.numpy(), density=True, histtype='stepfilled')\n",
    "# plt.hist(m3_samples.numpy(), density=True, histtype='stepfilled')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine all m distributions into a mixture\n",
    "# m = MixtureSameFamily(\n",
    "#     D.Categorical(torch.Tensor([0.33, 0.33, 0.33])),\n",
    "#     D.Independent(D.Normal(torch.Tensor([m1.loc, m2.loc, m3.loc]), torch.Tensor([m1.scale, m2.scale, m3.scale])),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset & dataloader\n",
    "train_ds = DistDataset(p, q, m, num_samples=NUM_SAMPLES)\n",
    "test_ds = DistDataset(p, q, m, num_samples=NUM_SAMPLES) # Test dataset is only of size batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloader\n",
    "train_dl = DataLoader(train_ds, batch_size=BS, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=BS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up viz\n",
    "fig, [[ax1,ax2,ax3], [ax4, ax5, ax6], [ax7, ax8, ax9]] = plt.subplots(3, 3,figsize=(15,12))\n",
    "\n",
    "line, = ax1.plot([0,1],[0,1])\n",
    "x, y = np.random.random((2, 500))\n",
    "scat1 = ax2.scatter(x,y,label='True p/q',alpha=0.9,s=10.,c='b')\n",
    "scat2 = ax2.scatter(x,y,label='CoB p/q',alpha=0.9,s=10.,c='r')\n",
    "test_line, = ax3.plot([0,1],[0,1])\n",
    "\n",
    "ax1.set_xlabel(\"Iteration\")\n",
    "ax1.set_ylabel(\"Train Loss\")\n",
    "ax1.set_xlim([0,NUM_EPOCHS*NUM_SAMPLES//BS])\n",
    "ax1.set_ylim([0,10])\n",
    "\n",
    "ax2.set_xlabel(\"Samples\")\n",
    "ax2.set_ylabel(\"Log Ratio\")\n",
    "ax2.legend(loc='best')\n",
    "ax2.set_xlim([-6,10])\n",
    "ax2.set_ylim([-1500,5000])\n",
    "\n",
    "ax3.set_xlabel(\"Iteration\")\n",
    "ax3.set_ylabel(\"Test Loss\")\n",
    "ax3.set_xlim([0,NUM_EPOCHS*NUM_SAMPLES//BS])\n",
    "ax3.set_ylim([0,10])\n",
    "\n",
    "line2, = ax4.plot([0,1],[0,1])\n",
    "x, y = np.random.random((2, 500))\n",
    "scat3 = ax5.scatter(x,y,label='True p/q',alpha=0.9,s=10.,c='b')\n",
    "scat4 = ax5.scatter(x,y,label='TRE p/q',alpha=0.9,s=10.,c='r')\n",
    "test_line2, = ax6.plot([0,1],[0,1])\n",
    "\n",
    "ax4.set_xlabel(\"Iteration\")\n",
    "ax4.set_ylabel(\"Train Loss\")\n",
    "ax4.set_xlim([0,NUM_EPOCHS*NUM_SAMPLES//BS])\n",
    "ax4.set_ylim([0,10])\n",
    "\n",
    "ax5.set_xlabel(\"Samples\")\n",
    "ax5.set_ylabel(\"Log Ratio\")\n",
    "ax5.legend(loc='best')\n",
    "ax5.set_xlim([-6,10])\n",
    "ax5.set_ylim([-1500,5000])\n",
    "\n",
    "ax6.set_xlabel(\"Iteration\")\n",
    "ax6.set_ylabel(\"Test Loss\")\n",
    "ax6.set_xlim([0,NUM_EPOCHS*NUM_SAMPLES//BS])\n",
    "ax6.set_ylim([0,10])\n",
    "\n",
    "\n",
    "line3, = ax7.plot([0,1],[0,1])\n",
    "scat5 = ax8.scatter(x,y,label='True p/q',alpha=0.9,s=10.,c='b')\n",
    "scat6 = ax8.scatter(x,y,label='TRE p/q',alpha=0.9,s=10.,c='r')\n",
    "test_line3, = ax9.plot([0,1],[0,1])\n",
    "\n",
    "ax7.set_xlabel(\"Iteration\")\n",
    "ax7.set_ylabel(\"Train Loss\")\n",
    "ax7.set_xlim([0,NUM_EPOCHS*NUM_SAMPLES//BS])\n",
    "ax7.set_ylim([0,10])\n",
    "\n",
    "ax8.set_xlabel(\"Samples\")\n",
    "ax8.set_ylabel(\"Log Ratio\")\n",
    "ax8.legend(loc='best')\n",
    "ax8.set_xlim([-6,10])\n",
    "ax8.set_ylim([-1500,5000])\n",
    "\n",
    "ax9.set_xlabel(\"Iteration\")\n",
    "ax9.set_ylabel(\"Test Loss\")\n",
    "ax9.set_xlim([0,NUM_EPOCHS*NUM_SAMPLES//BS])\n",
    "ax9.set_ylim([0,10])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "loss_store = []\n",
    "test_loss_store = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFIRM q_list_test in validation/visualization in Akash's code\n",
    "\n",
    "model_cob.train()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model_cob = model_cob.to(DEVICE)\n",
    "    \n",
    "i = 0\n",
    "# loss_crit = torch.nn.CrossEntropyLoss()\n",
    "loss_crit_cob = torch.nn.functional.cross_entropy\n",
    "\n",
    "\n",
    "for epoch in trange(NUM_EPOCHS):\n",
    "    for p_batch, q_batch, m_batch in iter(train_dl):\n",
    "        model_cob.train()\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        optim_cob.zero_grad()\n",
    "        \n",
    "        # CUDA\n",
    "        if torch.cuda.is_available():\n",
    "            p_batch, q_batch, m_batch = p_batch.unsqueeze(1).to(DEVICE), q_batch.unsqueeze(1).to(DEVICE), m_batch.unsqueeze(1).to(DEVICE)\n",
    "            \n",
    "        logP = model_cob(p_batch)\n",
    "        logQ = model_cob(q_batch)\n",
    "        logM = model_cob(m_batch)\n",
    "        \n",
    "        p_label = torch.empty(p_batch.shape[0], dtype=torch.long, device=DEVICE).fill_(0)\n",
    "        q_label = torch.empty(q_batch.shape[0], dtype=torch.long, device=DEVICE).fill_(1)\n",
    "        m_label = torch.empty(m_batch.shape[0], dtype=torch.long, device=DEVICE).fill_(2)\n",
    "        \n",
    "        loss_cob = loss_crit_cob(logP, p_label) + loss_crit_cob(logQ, q_label) + loss_crit_cob(logM, m_label)\n",
    "        loss_cob.backward()\n",
    "        optim_cob.step()\n",
    "        loss_store.append(loss_cob.item())\n",
    "\n",
    "        # Validation/Test\n",
    "        if i % 50 == 0:\n",
    "            model_cob.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for p_batch, q_batch, m_batch in iter(test_dl):\n",
    "                    gt_log_ratio_p_q, _, true_kl_p_q = get_gt_ratio_kl(p, q, m_batch, calc_true_kl=True)\n",
    "\n",
    "                    if torch.cuda.is_available():\n",
    "                        p_batch, q_batch, m_batch = p_batch.unsqueeze(1).to(DEVICE), q_batch.unsqueeze(1).to(DEVICE), m_batch.unsqueeze(1).to(DEVICE)\n",
    "                    \n",
    "                    logP = model_cob(p_batch)\n",
    "                    logQ = model_cob(q_batch)\n",
    "                    logM = model_cob(m_batch)\n",
    "\n",
    "#                     log_ratio_p_q_from_cob = logP[:, 0] - logP[:, 1]\n",
    "#                     kl_from_cob = torch.mean(log_ratio_p_q_from_cob)\n",
    "                    \n",
    "                    log_ratio_p_q_from_cob = logM[:, 0] - logM[:, 1]\n",
    "\n",
    "                    p_label = torch.empty(p_batch.shape[0], dtype=torch.long, device=DEVICE).fill_(0)\n",
    "                    q_label = torch.empty(q_batch.shape[0], dtype=torch.long, device=DEVICE).fill_(1)\n",
    "                    m_label = torch.empty(m_batch.shape[0], dtype=torch.long, device=DEVICE).fill_(2)\n",
    "                    \n",
    "                    test_loss_cob = loss_crit_cob(logP, p_label) + loss_crit_cob(logQ, q_label) + loss_crit_cob(logM, m_label)\n",
    "\n",
    "                    # Visualize\n",
    "                    line.set_data(range(len(loss_store)), loss_store)\n",
    "                    ax1.set_xlim( 0, len(loss_store) )\n",
    "                    \n",
    "                    scat1.set_offsets(np.vstack([m_batch.cpu().squeeze(), gt_log_ratio_p_q.cpu().detach()]).T)\n",
    "                    scat2.set_offsets(np.vstack([m_batch.cpu().squeeze(), log_ratio_p_q_from_cob.cpu().detach()]).T)\n",
    "\n",
    "                    ax2.set_xlim( -5., 5. )\n",
    "                    ax2.set_ylim( -400, 200)\n",
    "            \n",
    "                    test_loss_store.append(test_loss_cob.item())\n",
    "                    test_line.set_data(range(len(test_loss_store)), test_loss_store)\n",
    "                    ax3.set_xlim( 0, len(test_loss_store) )\n",
    "                    \n",
    "                    clear_output(wait=True)\n",
    "                    display(fig)\n",
    "                    break\n",
    "\n",
    "            model_cob.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    print('iteration: ',i)\n",
    "                    print('KLD: ', true_kl_p_q)\n",
    "                    print('CoB: ', kl_from_cob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_log_ratios(p, q, m1, samples):\n",
    "    p_lp = p.log_prob(samples.cpu())\n",
    "    q_lp = q.log_prob(samples.cpu())\n",
    "    m1_lp = m1.log_prob(samples.cpu())\n",
    "#     m2_lp = m2.log_prob(samples.cpu())\n",
    "#     m3_lp = m3.log_prob(samples.cpu())\n",
    "    \n",
    "#     return p_lp - q_lp,  p_lp - m1_lp, m1_lp - m2_lp, m2_lp - m3_lp, m3_lp - q_lp #p_lp - m_lp, q_lp - m_lp, m_lp - q_lp # p/q, p/m, q/m, m/q\n",
    "    return p_lp - q_lp #, p_lp - m2_lp, q_lp - m2_lp, m1_lp - m2_lp, m3_lp - m2_lp\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "with torch.no_grad():\n",
    "    model_cob.eval()\n",
    "    for p_batch, q_batch, m_batch1 in iter(test_dl):\n",
    "        if torch.cuda.is_available():\n",
    "            p_batch, q_batch, m_batch1 = p_batch.unsqueeze(1).to(DEVICE), q_batch.unsqueeze(1).to(DEVICE), m_batch1.unsqueeze(1).to(DEVICE)\n",
    "\n",
    "\n",
    "#         p_batch = torch.from_numpy(np.linspace(-1.5, 1.5, 1000)).unsqueeze(1).to(DEVICE)\n",
    "\n",
    "        logP1 = model_cob(p_batch).cpu()\n",
    "        log_ratio_p_q_from_p= logP1[:, 0] - logP1[:, 1]\n",
    "        \n",
    "        logP2 = model_cob(m_batch1).cpu()\n",
    "        log_ratio_p_q_from_m1 = logP2[:, 0] - logP2[:, 1]\n",
    "        \n",
    "        logP3 = model_cob(q_batch).cpu()\n",
    "        log_ratio_p_q_from_q = logP3[:, 0] - logP3[:, 1]\n",
    "        \n",
    "        true_log_ratio_p_q_from_p = get_gt_log_ratios(p, q, m, p_batch)\n",
    "        true_log_ratio_p_q_from_m1 = get_gt_log_ratios(p, q, m, m_batch1)\n",
    "        true_log_ratio_p_q_from_q = get_gt_log_ratios(p, q, m, q_batch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up viz\n",
    "fig, [ax4, ax1,ax2,ax3] = plt.subplots(1, 4,figsize=(10,3))\n",
    "p_batch = p_batch.cpu()\n",
    "\n",
    "p_samples = p.sample([1000])\n",
    "q_samples = q.sample([1000])\n",
    "m_samples= m.sample([1000])\n",
    "\n",
    "ax4.hist(p_samples.numpy(), density=True, histtype='stepfilled', label='p')\n",
    "ax4.hist(q_samples.numpy(), density=True, histtype='stepfilled', label='q')\n",
    "ax4.hist(m_samples.numpy(), density=True, histtype='stepfilled', label='m')\n",
    "\n",
    "\n",
    "\n",
    "scat1 = ax1.scatter(p_batch,true_log_ratio_p_q_from_p,label='True log p/q',alpha=0.9,s=1.,c='b')\n",
    "scat2 = ax1.scatter(p_batch,log_ratio_p_q_from_p,label='sDRE log p/q',alpha=0.9,s=1.,c='r')\n",
    "\n",
    "scat3 = ax2.scatter(m_batch1.cpu(),true_log_ratio_p_q_from_m1,label='True log p/q',alpha=0.9,s=1.,c='b')\n",
    "scat4 = ax2.scatter(m_batch1.cpu(),log_ratio_p_q_from_m1,label='sDRE log p/q',alpha=0.9,s=1.,c='r')\n",
    "\n",
    "scat5 = ax3.scatter(q_batch.cpu(),true_log_ratio_p_q_from_q,label='True log p/q',alpha=0.9,s=1.,c='b')\n",
    "scat6 = ax3.scatter(q_batch.cpu(),log_ratio_p_q_from_q,label='sDRE log p/q',alpha=0.9,s=1.,c='r')\n",
    "\n",
    "ylim = [-300, 200]\n",
    "xlim = [-3, 3]\n",
    "\n",
    "ax1.set_ylabel(\"Log Ratio\")\n",
    "ax1.legend(loc='lower left', prop={'size': 8})\n",
    "ax1.set_xlim(xlim)\n",
    "ax1.set_ylim(ylim)\n",
    "ax1.set_xlabel('p')\n",
    "\n",
    "ax2.set_ylabel(\"Log Ratio\")\n",
    "ax2.legend(loc='lower left', prop={'size': 8})\n",
    "ax2.set_xlim(xlim)\n",
    "ax2.set_ylim(ylim)\n",
    "ax2.set_xlabel('m')\n",
    "\n",
    "ax3.set_ylabel(\"Log Ratio\", rotation=270, labelpad=10)\n",
    "ax3.legend(loc='lower left', prop={'size': 8})\n",
    "ax3.set_xlim(xlim)\n",
    "ax3.set_ylim(ylim)\n",
    "ax3.set_xlabel('q')\n",
    "ax3.yaxis.tick_right()\n",
    "ax3.yaxis.set_label_position(\"right\")\n",
    "\n",
    "\n",
    "ax4.set_xlim([-2,2])\n",
    "ax4.set_ylim([0, 3])\n",
    "ax4.legend()\n",
    "\n",
    "\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "ax2.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0, hspace=0.0)\n",
    "\n",
    "plt.savefig('1D_demo_cob_K=1_cauchy_logpq.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(p_samples.numpy(), density=True, histtype='stepfilled', label='p')\n",
    "ax.hist(q_samples.numpy(), density=True, histtype='stepfilled', label='q')\n",
    "ax.hist(m_samples.numpy(), density=True, histtype='stepfilled', label='m')\n",
    "ax.set_xlim([-2,2])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
